\section{Conclusions}
\label{sec:conclusions}

In this assignment, we created a generative model to do concept tagging.
The best model was the improved one described in \cref{sec:improvements} using 4-gram and Kneser-Ney smoothing for the underlying language model.
The inclusion of words in the \texttt{O} tags brought a significant performance improvement.
The model reached $82.44\%$ precision, $83.04\%$ recall and a F1 score of $82.74\%$ on the test set.
